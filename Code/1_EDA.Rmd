---
title: "Exploratory Data Analysis"
output: beamer_presentation 
---

### **Loading libraries**

The below code chunk loads the libraries we will be using in our analysis:

```{r, setup, include=FALSE}
library(moments)
library(tseries)
library(forecast)
```

### **Reading and cleaning data**

First, we input our stock data.

Our stock data consists of the following indices between 2000 and 2020:

-   S&P500

-   DOWJONES

-   NYSE100

***Important***: Before running the code below, make sure your Knit directory is 'Document Directory'. This can be done by clicking the drop-down menu next to Knit, going to Knit directory and clicking on Document Directory.

```{r}
setwd("..")
sp <- read.csv('Data/sp500.csv')
dow<-read.csv("Data/dowjones.csv")
nas<-read.csv("Data/nasdaq.csv")
```

Now we will rename some columns and fixing Date and number formats:

```{r}
#Renaming columns
colnames(sp) <- c("Date","Price")
colnames(dow) <- c("Date","Price")
colnames(nas) <- c("Date","Price")

#Fixing the Date format
sp$Date<-as.Date(sp$Date, format="%d/%m/%Y")
dow$Date<-as.Date(dow$Date, format="%d/%m/%Y")
nas$Date<-as.Date(nas$Date, format="%d/%m/%Y")

#Fixing numeric format
dow$Price <- as.numeric(gsub(",", "", dow$Price))

#Getting an overall idea of our datasets
str(sp)
str(dow)
str(nas)
```

### **Initial Plots**

We will start off by making a graph of index price against time for each indices, to get an idea of what our data looks like.

```{r}
#Plotting Price against Date for each index
plot(sp, col='red',type='l',ylim=c(1000,32000))
lines(dow, col='blue')
lines(nas, col='green')
legend("topleft", legend=c("SP500", "DowJones", "NASDAQ"),
       col=c("red", "blue", "green"), lty=c(1,1,1))
```

They all follow the same basic pattern, which is what we would expect, with the iconic fall in stock-price during the 2008-2009 period of the 'Great Recession'.

However, the stock price directly does not give us much information. Instead, we will take at the **daily log stock returns**.

```{r}
sp_logret <- diff(log(sp$Price))
dow_logret <- diff(log(dow$Price))
nas_logret <- diff(log(nas$Price))

plot(sp$Date[-length(sp$Date)],sp_logret,type='l',xlab="Date",ylab="SP500")
#title(main="LOG RETURN",cex.main=2.2)
plot(dow$Date[-length(dow$Date)],dow_logret, type='l',xlab="Date",ylab="DJ")
plot(nas$Date[-length(nas$Date)],nas_logret, type='l',xlab="Date",ylab="NASDAQ")
```

We can see that the returns average around 0% with very high variability during 2008-2009 (caused by the Great Recession) and during 2020 (caused by COVID-19).

Let us now plot the density of the returns to try to understand the distribution which will be helpful when we try to model the returns later one:

```{r}
plot(density(sp_logret),ylab="SP500",main="Density SP Log_Ret")
plot(density(dow_logret),ylab="DJ",main="Density DJ Log_Ret")
plot(density(nas_logret),ylab="NASDAQ",main="Density NAS Log_Ret")
```

The returns look like they follow a normal distribution. So, we will make qq-plots to further confirm this:

```{r}
qqnorm(sp_logret,main="QPlot SP Log_Ret")
qqline(sp_logret,col='red')

qqnorm(dow_logret,main="QPlot DJ Log_Ret")
qqline(dow_logret,col='red')

qqnorm(nas_logret,main="QPlot DJ Log_Ret")
qqline(nas_logret,col='red')
```

The log-returns have much heavier tails than the normal distribution, which suggests that it might follow a Student's t-distribution.

### **Calculating descriptive statistics**

Let us now obtain some sample statistics of our data. We will first use summary():

```{r}
summary(sp_logret)
summary(dow_logret)
summary(nas_logret)
```

Now we will calculate the skewness of our data:

```{r}
skewness(sp_logret)
skewness(dow_logret)
skewness(nas_logret)
```

The skewness of our indexes are not equal to 0 which indicates that our log-returns might not be normally distributed. Let's also look at the tails of the distribution by calculating the sample kurtosis:

```{r}
kurtosis(sp_logret)
kurtosis(dow_logret)
kurtosis(nas_logret)
```

Let's also calculate the mean of our log returns as well:

```{r}
mean(sp_logret)
mean(dow_logret)
mean(nas_logret)
```

```{r}
lag.length = 50

Box.test(sp_logret, lag=lag.length, type="Ljung-Box")

Box.test(dow_logret, lag=lag.length, type="Ljung-Box")

Box.test(nas_logret, lag=lag.length, type="Ljung-Box")
```

The p-value is very small which means we reject the null hypothesis that our correlations are 0. This means our data is not stationary and we might not use a GARCH model on log-returns directly.

We also plot the ACF of our indexes to see how our data is correlated:

```{r}
acf(sp_logret,main="SP Log_Ret")
acf(dow_logret,main="DJ Log_Ret")
acf(nas_logret,main="NAS Log_Ret")
```

As you can see above there is serious correlation on the first lag, again confirm that our series is not stationary, hence we cannot apply a GARCH model directly on the log-returns.

This means we have to build a mean-equation in such a way that the residuals should be stationary. We will also check certain conditions on our residuals such as if they are normal.

### Building a mean-equation

To build our mean equation we will be using auto.arima() which will automatically pick the parameters of the arima model that has the lowest AIC.

```{r}
sp_ar <- auto.arima(sp_logret , max.order = c(3 , 0 ,3) , trace = T,  max.d = 0, ic = 'aic')


dow_ar <- auto.arima(dow_logret , max.order = c(3 , 0 ,3) , trace = T ,   max.d = 0, ic = 'aic')


nas_ar <- auto.arima(nas_logret , max.order = c(3 , 0 ,3) , trace = T ,  max.d = 0, ic = 'aic')
```

So the best models are the following:

-   **sp:** AR(1)

-   **dow:** AR(1)

-   **nas:** ARMA(3,0,2)

You can see more detailed info below:

```{r}
sp_ar
dow_ar
nas_ar
```

### Doing diagnostic checks on residuals

Let's first take a look at how our residuals look:

```{r}
sp_residuals <- sp_ar$residuals
dow_residuals <- dow_ar$residuals
nas_residuals <- nas_ar$residuals

plot(sp_residuals, type='l')
plot(dow_residuals, type='l')
plot(nas_residuals, type='l')
```

Let's plot ACF and PACF of our residuals.

```{r}
acf(sp_residuals)
acf(dow_residuals)
acf(nas_residuals)
```

Obtaining some statistics:

```{r}
summary(sp_residuals)
summary(dow_residuals)
summary(nas_residuals)
```

```{r}
skewness(sp_residuals)
skewness(dow_residuals)
skewness(nas_residuals)
```

```{r}
kurtosis(sp_residuals)
kurtosis(dow_residuals)
kurtosis(nas_residuals)
```

```{r}
mean(sp_residuals)
mean(dow_residuals)
mean(nas_residuals)
```

```{r}
qqnorm(sp_residuals,main="QPlot SP Log_Ret")
qqline(sp_residuals,col='red')

qqnorm(dow_residuals,main="QPlot DJ Log_Ret")
qqline(dow_residuals,col='red')

qqnorm(nas_logret,main="QPlot DJ Log_Ret")
qqline(nas_logret,col='red')
```

We can see that our residuals are fairly symmetrical but it has very high kurtosis, meaning we agree with our previous stance that an appropriate distribution would be the Student's t-distribution.

Now let's do a box test to check if our residuals are stationary.

```{r}
lag.length = 50

Box.test(sp_residuals, lag=lag.length, fitdf=1, type="Ljung-Box")

Box.test(dow_residuals, lag=lag.length, fitdf=1, type="Ljung-Box")

Box.test(nas_residuals, lag=lag.length, fitdf=5, type="Ljung-Box")
```

No dice! Our data is still non-stationary.

### Detecting change points in our log-returns and adjusting our data

As a last-ditch effort, we will adjust our data with change-points to try to make it stationary.

Change points are intervals within our data in which the mean is different than the mean of the rest of the data. We have used [H. Cho and P. Fryzlewicz (2021)'s](https://arxiv.org/abs/2011.13884) algorithm to detect change points in our data (the code can be found [here](https://github.com/haeran-cho/wcm.gsa)) and remove these change points from our data.

```{r}
source('change_points.R')

sp_changepoint<-wcm.gsa(sp_logret, double.cusum = TRUE)

mean_sp <- sp_logret * 0
position <- c(0, sp_changepoint$cp, length(sp_logret))
for(i in 1:(length(sp_changepoint$cp) + 1)){
  int <- (position[i] + 1):position[i + 1]
  mean_sp[int] <- mean(sp_logret[int])
}
sp_logret_changepoint <- sp_logret - mean_sp
```

```{r}
dow_changepoint<-wcm.gsa(dow_logret, double.cusum = TRUE)

mean_dow <- dow_logret * 0
position <- c(0, dow_changepoint$cp, length(dow_logret))
for(i in 1:(length(dow_changepoint$cp) + 1)){
  int <- (position[i] + 1):position[i + 1]
  mean_dow[int] <- mean(dow_logret[int])
}

dow_logret_changepoint <- dow_logret - mean_dow
```

```{r}
nas_changepoint<-wcm.gsa(nas_logret, double.cusum = TRUE)

mean_nas <- nas_logret * 0
position <- c(0, nas_changepoint$cp, length(nas_logret))
for(i in 1:(length(nas_changepoint$cp) + 1)){
  int <- (position[i] + 1):position[i + 1]
  mean_nas[int] <- mean(nas_logret[int])
}

nas_logret_changepoint <- nas_logret - mean_nas
```

Now, let us see if removing the change-points have made our data stationary

```{r}
lag.length = 50

Box.test(sp_logret_changepoint, lag=lag.length, type="Ljung-Box")

Box.test(dow_logret_changepoint, lag=lag.length, type="Ljung-Box")

Box.test(nas_logret_changepoint, lag=lag.length, type="Ljung-Box")
```

The test says our data is non-stationary. Let's see if our residuals are stationary.

```{r}
sp_ar_changepoint <- auto.arima(sp_logret_changepoint , max.order = c(3 , 0 ,3) , trace = T,  max.d = 0, ic = 'aic')


dow_ar_changepoint <- auto.arima(dow_logret_changepoint , max.order = c(3 , 0 ,3) , trace = T ,   max.d = 0, ic = 'aic')


nas_ar_changepoint <- auto.arima(nas_logret_changepoint , max.order = c(3 , 0 ,3) , trace = T ,  max.d = 0, ic = 'aic')
```

```{r}
sp_residuals_changepoint <- sp_ar_changepoint$residuals
dow_residuals_changepoint <- dow_ar_changepoint$residuals
nas_residuals_changepoint <- nas_ar_changepoint$residuals

lag.length = 50

Box.test(sp_residuals_changepoint, lag=lag.length, fitdf=6, type="Ljung-Box")

Box.test(dow_residuals_changepoint, lag=lag.length, fitdf=1, type="Ljung-Box")

Box.test(nas_residuals_changepoint, lag=lag.length, fitdf=5, type="Ljung-Box")
```

Does not work (Add comment on using non-stationary data and no changepoints) Because of both of our data

### Outputting Files

```{r}
setwd('..')
write.csv(sp_logret, 'Data/Processed/sp_logret.csv', row.names=T)
write.csv(dow_logret, 'Data/Processed/dow_logret.csv', row.names=T)
write.csv(nas_logret, 'Data/Processed/nas_logret.csv', row.names=T)

write.csv(sp_residuals, 'Data/Processed/sp_residuals.csv', row.names=T)
write.csv(dow_residuals, 'Data/Processed/dow_residuals.csv', row.names=T)
write.csv(nas_residuals, 'Data/Processed/nas_residuals.csv', row.names=T)
```
